"""
Google News RSS ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼

NewsAPIã‚’è£œå®Œã™ã‚‹ãŸã‚ã€Google Newsã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—
"""
import requests
import xml.etree.ElementTree as ET
from datetime import datetime
from typing import List, Optional
from urllib.parse import quote
from concurrent.futures import ThreadPoolExecutor, as_completed
from models.news_dto import NewsDTO, NewsFetchResult


class GoogleNewsClient:
    """Google News RSS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    BASE_URL = "https://news.google.com/rss"
    
    # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆåŠ¹ç‡åŒ–ï¼š5å€‹ã«å³é¸ï¼‰
    SEARCH_QUERIES = [
        "forex USD JPY yen",           # ç‚ºæ›¿å…¨èˆ¬
        "Federal Reserve BOJ policy",  # ä¸­å¤®éŠ€è¡Œ
        "stock market Nikkei S&P",     # æ ªå¼å¸‚å ´
        "inflation GDP economy",       # çµŒæ¸ˆæŒ‡æ¨™
        "oil gold commodity price",    # ã‚³ãƒ¢ãƒ‡ã‚£ãƒ†ã‚£
    ]
    
    # çµŒæ¸ˆé–¢é€£ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã«å«ã¾ã‚Œã‚‹ã¹ãï¼‰
    ECONOMY_KEYWORDS = [
        # è‹±èª
        "market", "stock", "economy", "economic", "financial", "finance",
        "bank", "fed", "boj", "ecb", "rate", "rates", "inflation",
        "gdp", "growth", "trade", "trading", "invest", "investment",
        "bond", "yield", "currency", "forex", "dollar", "yen", "euro",
        "oil", "gold", "commodity", "index", "nasdaq", "dow", "nikkei",
        "earnings", "profit", "revenue", "quarter", "fiscal",
        # æ—¥æœ¬èª
        "çµŒæ¸ˆ", "é‡‘è", "æ ªå¼", "ç‚ºæ›¿", "æ—¥éŠ€", "å¸‚å ´", "æŠ•è³‡",
        "å††å®‰", "å††é«˜", "ãƒ‰ãƒ«", "é‡‘åˆ©", "ã‚¤ãƒ³ãƒ•ãƒ¬", "æ™¯æ°—",
    ]
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })
    
    def fetch_top_stories(self, topic: str = "BUSINESS") -> NewsFetchResult:
        """
        ãƒˆãƒ”ãƒƒã‚¯åˆ¥ãƒˆãƒƒãƒ—ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã‚’å–å¾—
        
        Args:
            topic: BUSINESS, TECHNOLOGY, WORLD ç­‰
        
        Returns:
            NewsFetchResult
        """
        url = f"{self.BASE_URL}/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtVnVHZ0pWVXlnQVAB"
        # Business topic URL
        if topic == "BUSINESS":
            url = f"{self.BASE_URL}/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGx6TVdZU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US:en"
        
        return self._fetch_rss(url, "Google News Top Stories")
    
    def search(self, query: str) -> NewsFetchResult:
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
        
        Args:
            query: æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰
        
        Returns:
            NewsFetchResult
        """
        encoded_query = quote(query)
        url = f"{self.BASE_URL}/search?q={encoded_query}&hl=en-US&gl=US&ceid=US:en"
        
        return self._fetch_rss(url, f"Google News Search: {query}")
    
    def _fetch_rss(self, url: str, source_name: str) -> NewsFetchResult:
        """RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ãƒ‘ãƒ¼ã‚¹"""
        try:
            response = self.session.get(url, timeout=8)
            response.raise_for_status()
            
            root = ET.fromstring(response.content)
            channel = root.find("channel")
            
            if channel is None:
                return NewsFetchResult(
                    success=False,
                    error_message="Invalid RSS feed",
                    source_api=source_name,
                )
            
            news_list = []
            for item in channel.findall("item"):
                try:
                    title = item.find("title")
                    link = item.find("link")
                    pub_date = item.find("pubDate")
                    source = item.find("source")
                    description = item.find("description")
                    
                    # æ—¥æ™‚ãƒ‘ãƒ¼ã‚¹
                    published_at = datetime.now()
                    if pub_date is not None and pub_date.text:
                        try:
                            published_at = datetime.strptime(
                                pub_date.text, 
                                "%a, %d %b %Y %H:%M:%S %Z"
                            )
                        except ValueError:
                            pass
                    
                    dto = NewsDTO(
                        title=title.text if title is not None else "",
                        description=description.text if description is not None else "",
                        source_name=source.text if source is not None else "Google News",
                        published_at=published_at,
                        region="foreign",
                        url=link.text if link is not None else None,
                    )
                    
                    if dto.title.strip():
                        news_list.append(dto)
                        
                except Exception:
                    continue
            
            return NewsFetchResult(
                success=True,
                news_list=news_list,
                source_api=source_name,
            )
            
        except requests.RequestException as e:
            return NewsFetchResult(
                success=False,
                error_message=str(e),
                source_api=source_name,
            )
    
    def _is_economy_related(self, title: str) -> bool:
        """ã‚¿ã‚¤ãƒˆãƒ«ãŒçµŒæ¸ˆé–¢é€£ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        title_lower = title.lower()
        for keyword in self.ECONOMY_KEYWORDS:
            if keyword.lower() in title_lower:
                return True
        return False
    
    def fetch_economy_news(self) -> NewsFetchResult:
        """
        çµŒæ¸ˆé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ã¾ã¨ã‚ã¦å–å¾—ï¼ˆä¸¦åˆ—å‡¦ç†ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ä»˜ãï¼‰
        """
        all_news = []
        seen_urls = set()
        filtered_count = 0
        
        # ä¸¦åˆ—ã§ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œï¼ˆæœ€å¤§3ã‚¹ãƒ¬ãƒƒãƒ‰ï¼‰
        with ThreadPoolExecutor(max_workers=3) as executor:
            futures = {executor.submit(self.search, query): query for query in self.SEARCH_QUERIES}
            
            for future in as_completed(futures, timeout=30):
                try:
                    result = future.result(timeout=10)
                    if result.success:
                        for news in result.news_list:
                            if news.url and news.url not in seen_urls:
                                if self._is_economy_related(news.title):
                                    all_news.append(news)
                                    seen_urls.add(news.url)
                                else:
                                    filtered_count += 1
                except Exception:
                    continue
        
        print(f"   ğŸ“° Google News: {len(all_news)}ä»¶å–å¾— ({filtered_count}ä»¶ã‚’çµŒæ¸ˆé–¢é€£å¤–ã¨ã—ã¦é™¤å¤–)")
        
        return NewsFetchResult(
            success=True,
            news_list=all_news,
            source_api="Google News (Economy)",
        )
    
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§ãƒ¡ã‚½ãƒƒãƒ‰åã‚‚æ®‹ã™
    def fetch_forex_news(self) -> NewsFetchResult:
        """ç‚ºæ›¿é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆfetch_economy_newsã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰"""
        return self.fetch_economy_news()


def fetch_google_news() -> NewsFetchResult:
    """Google Newsã‹ã‚‰ãƒ“ã‚¸ãƒã‚¹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆç°¡æ˜“é–¢æ•°ï¼‰"""
    client = GoogleNewsClient()
    return client.fetch_top_stories("BUSINESS")


def fetch_google_economy_news() -> NewsFetchResult:
    """Google Newsã‹ã‚‰çµŒæ¸ˆé–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆç°¡æ˜“é–¢æ•°ï¼‰"""
    client = GoogleNewsClient()
    return client.fetch_economy_news()


# å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§é–¢æ•°åã‚‚æ®‹ã™
def fetch_google_forex_news() -> NewsFetchResult:
    """Google Newsã‹ã‚‰ç‚ºæ›¿é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’å–å¾—ï¼ˆfetch_google_economy_newsã¸ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼‰"""
    return fetch_google_economy_news()
